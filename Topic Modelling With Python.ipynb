{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52acd554",
   "metadata": {},
   "source": [
    "https://thecleverprogrammer.com/2023/02/13/topic-modelling-using-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7989dc9",
   "metadata": {},
   "source": [
    "# 1. Importing the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943aced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34fa9c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\karki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\karki\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81175829",
   "metadata": {},
   "source": [
    "# 2. Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d0d3127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data analysis is the process of inspecting and...</td>\n",
       "      <td>Best Books to Learn Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The performance of a machine learning algorith...</td>\n",
       "      <td>Assumptions of Machine Learning Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You must have seen the news divided into categ...</td>\n",
       "      <td>News Classification with Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When there are only two classes in a classific...</td>\n",
       "      <td>Multiclass Classification Algorithms in Machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Multinomial Naive Bayes is one of the vari...</td>\n",
       "      <td>Multinomial Naive Bayes in Machine Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  Data analysis is the process of inspecting and...   \n",
       "1  The performance of a machine learning algorith...   \n",
       "2  You must have seen the news divided into categ...   \n",
       "3  When there are only two classes in a classific...   \n",
       "4  The Multinomial Naive Bayes is one of the vari...   \n",
       "\n",
       "                                               Title  \n",
       "0                  Best Books to Learn Data Analysis  \n",
       "1         Assumptions of Machine Learning Algorithms  \n",
       "2          News Classification with Machine Learning  \n",
       "3  Multiclass Classification Algorithms in Machin...  \n",
       "4        Multinomial Naive Bayes in Machine Learning  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/articles.csv\", encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "180bf88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "News Classification with Machine Learning                    2\n",
       "Best Books to Learn Data Analysis                            1\n",
       "Tata Motors Stock Price Prediction with Machine Learning     1\n",
       "Mean Shift Clustering in Machine Learning                    1\n",
       "BIRCH Clustering in Machine Learning                         1\n",
       "Agglomerative Clustering in Machine Learning                 1\n",
       "DBSCAN Clustering in Machine Learning                        1\n",
       "K-Means Clustering in Machine Learning                       1\n",
       "Animated Scatter Plot using Python                           1\n",
       "Apple Stock Price Prediction with Machine Learning           1\n",
       "For Loop Over Keys and Values in a Python Dictionary         1\n",
       "Best Books to Learn Deep Learning                            1\n",
       "Applications of Deep Learning                                1\n",
       "Introduction to Recommendation Systems                       1\n",
       "Use Cases of Different Machine Learning Algorithms           1\n",
       "Naive Bayes Algorithm in Machine Learning                    1\n",
       "Health Insurance Premium Prediction with Machine Learning    1\n",
       "Clustering Algorithms in Machine Learning                    1\n",
       "Assumptions of Machine Learning Algorithms                   1\n",
       "Types of Neural Networks                                     1\n",
       "Multilayer Perceptron in Machine Learning                    1\n",
       "Language Detection with Machine Learning                     1\n",
       "Voice Recorder using Python                                  1\n",
       "Best Python Frameworks to Build APIs                         1\n",
       "Best Resources to Learn Python                               1\n",
       "Best Books to Learn Computer Vision                          1\n",
       "Squid Game Sentiment Analysis using Python                   1\n",
       "Pfizer Vaccine Sentiment Analysis using Python               1\n",
       "Send Instagram Messages using Python                         1\n",
       "Best Books to Learn NLP                                      1\n",
       "Multinomial Naive Bayes in Machine Learning                  1\n",
       "Multiclass Classification Algorithms in Machine Learning     1\n",
       "Swap Items of a Python List                                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a82a66ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86380cb",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae93c4",
   "metadata": {},
   "source": [
    "As we are working with textual data, it is essential to clean it by removing punctuation and stop words, as they do not contribute to the task and may introduce complications.\n",
    "\n",
    "For that, we will create a function called `preprocess_text()` and then apply it to the Article feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56de8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    A function that takes in text and cleans it from punctation, stop-words to lemmatization.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. First conver the text into lower-case:\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove the punctuations:\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 3. Tokenize the text:\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # 4. Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # 5. Lemmatization:\n",
    "    lemma = WordNetLemmatizer()\n",
    "    clean_tokens = [lemma.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # 6. Finally join the tokens to form a cleaned text:\n",
    "    pre_processed_text = ' '.join(clean_tokens)\n",
    "    \n",
    "    return pre_processed_text\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6f10f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data analysis is the process of inspecting and exploring data generated by a particular population to find the information needed to make decisions and draw conclusions. With the use of data in decision making, most businesses today need data analysts. So, if you want to know about the best books to learn data analysis, this article is for you. In this article, I will introduce you to some of the best books to learn data analysis.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "364b35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Article'] = data['Article'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5da99d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data analysis process inspecting exploring data generated particular population find information needed make decision draw conclusion use data decision making business today need data analyst want know best book learn data analysis article article introduce best book learn data analysis'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Article'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784e285",
   "metadata": {},
   "source": [
    "# 4. Creating the vector space for the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c2e6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(data['Article'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e3bfecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34x413 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 908 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31673e6e",
   "metadata": {},
   "source": [
    "The resulted value will be a sparse matrix, and the if we convert the first element to an array, it would look like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46a85a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.36646841,\n",
       "        0.16015137, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0829327 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2053336 , 0.        , 0.        , 0.        ,\n",
       "        0.24431227, 0.        , 0.        , 0.        , 0.16015137,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16015137, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.47676947, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32030273, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16015137, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16015137, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13140908, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16015137, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.14333821, 0.        ,\n",
       "        0.16015137, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09341385,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09341385, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13808097, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13140908, 0.16015137, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10820386, 0.16015137, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13140908, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16015137, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16015137,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10820386, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09341385, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06264842, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23808800",
   "metadata": {},
   "source": [
    "# 5. Using LDA for topic assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15e3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279306d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
